####  http和rpc区别 

 1.协议不同 http一般为标准文本格式比如html json 。rpc可以自定义二进制协议 增加效率 比如protobuf

 2.通信方面 http一般是请求+响应模型 rpc可以在这个基础上做双向通行（比如grpc可以做流式传输）

3.http适合跨平台通信，浏览器和服务器通信。 rpc适合与需要低延迟，高效的服务通信。  

#### 1.请详细介绍一下TCP 的三次握手机制，为什么要三次握手？

握手机制主要就是为了保证可靠性和通过seq保证数据包的顺序性

客户端A 服务端B

第一次：A客户端向B发送请求报文段，首部中同步位SYN=1，同时选择一个初始化序列seq=x,TCP客户进程进入SYN-SENT（同步已发送）状态。

第二次：B收到请求，向A发送确认报文，SYN和ACK都设置为1，确认号是ack=x+1，同时选择一个随机序列seq=y，TCP服务器进程进入SYN-RCVD（同步收到）状态

第三次：TCP客户进程收到后再向B进行确认，确认报文ACK设置为1，确认号ack=y+1,序列号seq=x+1,此时A就进入ESTABLISHED（已建立连接）状态，B收到A的确认也进入ESTABLISHED（已建立连接）状态

为什么三次握手：三次握手可以确保连接的唯一性，避免旧连接的问题。 如果没有三次握手，可能会出现由于旧连接的缓存导致的连接建立错误、通过三次握手，可以防止网络攻击者模拟客户端或服务器发送伪造的连接请求。 攻击者必须知道双方的序列号和确认号才能伪造连接，而这些信息只有在三次握手中才会交换。

**为什么要三次握手，两次不行吗？**

A为什么要最后一次确定：防止已失效的连接请求报文段突然又传送到B，因此产生错误（类似比如A往B发送SYN请求，突然在中间因为网络波动卡主了，然后A一直得不到B的回应会认为没有成功从而重发，重发成功后突然之前那个卡住的请求又正常传入B了，B会误认为是客户端又发起了一个新的连接，从而在两次握手之后，进入等待数据状态，服务端认为是两个连接，而客户端认为是一个连接，造成了状态不一致问题）

**SYN 超时了怎么处理？**

也就是 client 发送 SYN 至 server 然后就挂了，此时 server 发送 SYN+ACK 就一直得不到回复，怎么办？

我脑海中一想到的就是重试，但是不能连续快速重试多次，你想一下，假设 client 掉线了，你总得给它点时间恢复吧，所以呢需要**慢慢重试，阶梯性重试**。

在 Linux 中就是默认重试 5 次，并且就是阶梯性的重试，间隔就是1s、2s、4s、8s、16s，再第五次发出之后还得等 32s 才能知道这次重试的结果，所以说总共等63s 才能断开连接。

**SYN Flood 攻击**

 SYN 超时需要耗费服务端 63s 的时间断开连接，也就说 63s 内服务端需要保持这个资源，所以不法分子就可以构造出大量的 client 向 server 发 SYN 但就是不回 server 使得 server 的 SYN 队列耗尽，无法处理正常的建连请求。

处理：调整 tcp_synack_retries 减少重试的次数，设置 tcp_max_syn_backlog 增加 SYN 队列数，设置 tcp_abort_on_overflow SYN 队列满了直接拒绝连接

https://blog.csdn.net/qzcsu/article/details/72861891

https://mp.weixin.qq.com/s/LUtk6u_zv0w8g8GIGWEuCw

https://mp.weixin.qq.com/s/tRXlq1hErqKQLMMLcxoXvg

#### 2.讲一下HTTP与HTTPS 的区别。

HTTP 是一种 超文本传输协议(Hypertext Transfer Protocol)，HTTP 是一个在计算机世界里专门在两点之间传输文字、图片、音频、视频等超文本数据的约定和规范

而 HTTPS 的全称是 Hypertext Transfer Protocol Secure，从名称我们可以看出 HTTPS 要比 HTTPS 多了 secure 安全性这个概念，实际上， HTTPS 并不是一个新的应用层协议，它其实就是 HTTP + TLS/SSL 协议组合而成，而安全性的保证正是 TLS/SSL 所做的工作。也就是说，HTTPS 就是身披了一层 SSL 的 HTTP。

HTTP 是未经安全加密的协议，它的传输过程容易被攻击者监听、数据容易被窃取、发送方和接收方容易被伪造；

而 HTTPS 是安全的协议，它通过 密钥交换算法 - 签名算法 - 对称加密算法 - 摘要算法 能够解决上面这些问题。

HTTP 的默认端口是 80，而 HTTPS 的默认端口是 443。

https://mp.weixin.qq.com/s/t7ZYT6wBBbFYVBPOSztpRg

#### 3.Session和cookie的区别。

(1)cookie数据存放在客户的浏览器上，session数据放在服务器上

(2)cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗,如果主要考虑到安全应当使用session

(3)session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能，如果主要考虑到减轻服务器性能方面，应当使用COOKIE

(4)单个cookie在客户端的限制是3K，就是说一个站点在客户端存放的COOKIE不能3K。

(5)所以：将登陆信息等重要信息存放为SESSION;其他信息如果需要保留，可以放在COOKIE中

https://blog.csdn.net/chen13333336677/article/details/100939030



#### 4.TCP的四次挥手，为什么要有TIME_WAIT 状态，为什么需要四次握手

第一次：A把连接释放报文的首部终止控制位FIN设置为1，序列号seq=u(传输最后一个字节的序列号加1)，A进入FIN-WAIT-1（终止等待1）状态

第二次：收到连接释放报文进行确认，设置ACK=1，确认号为ack=u+1，自己的序列号seq=v（传输最后一个字节的序列号加1），B进入CLOSE-WAIT（关闭等待）状态

TCP服务器要通知高层服务器，A收到B的确认报文后进入FIN-WAIT-2（终止等待2）状态，等待B发送连接释放请求（这个阶段还可以接受未发送完的消息）

第三次：B发出连接释放报文段，FIN设置为1，B的序列号为w，发送确认号ack=u+1,B进入LAST-ACK（最后确认）状态，等待A确认。

第四次：A发送确定报文段ACK设置为1，确认号ack=w+1，序列号seq=u+1，然后进入到TIME-WAIT（时间等待）状态。必须要经过时间等待计时器设置的时间2MSl后，A才进入CLOSE状态



**为什么要等待2MSL时间：**

为了保证A发送的最后一个ACK报文段能够到达B（如果报文丢失，B会进行重发FIN包，A重新接收，重新计时）

可以保证两次内的数据问题。

防止之前的报文包到新的连接，我看了一下因为2MSL，可以保证之前可能没有接受的报文包出现的时候早已经没用了。使本链接持续时间内所产生的所有报文段都从网络中消失。从保证在关闭连接后不会有还在网络中滞留的报文段去骚扰服务器。

**等待 2MSL 会产生什么问题？**

如果服务器主动关闭大量的连接，那么会出现大量的资源占用，需要等到 2MSL 才会释放资源。

如果是客户端主动关闭大量的连接，那么在 2MSL 里面那些端口都是被占用的，端口只有 65535 个，如果端口耗尽了就无法发起送的连接了，不过我觉得这个概率很低，这么多端口你这是要建立多少个连接？

**如何解决 2MSL 产生的问题？**

快速回收，即不等 2MSL 就回收， Linux 的参数是 tcp_tw_recycle，还有 tcp_timestamps 不过默认是打开的。

TCP还有个保活计时器（客户端没有回应，认为故障，连接关闭）





#### 5.http1.0和http1.1有什么区别。

**长连接** : 在HTTP/1.0中，默认使用的是短连接，也就是说每次请求都要重新建立一次连接。HTTP 是基于TCP/IP协议的,每一次建立或者断开连接都需要三次握手四次挥手的开销，如果每次请求都要这样的话，开销会比较大。因此最好能维持一个长连接，可以用个长连接来发多个请求。HTTP 1.1起，默认使用长连接 ,默认开启Connection： keep-alive。 HTTP/1.1的持续连接有非流水线方式和流水线方式 。流水线方式是客户在收到HTTP的响应报文之前就能接着发送新的请求报文。与之相对应的非流水线方式是客户在收到前一个响应后才能发送下一个请求。

**错误状态响应码** :在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。

**缓存处理** :在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。

**带宽优化及网络连接的使用** :HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。



HTTP 1.0 仅仅提供了最基本的认证，这时候用户名和密码还未经加密，因此很容易收到窥探。

HTTP 1.0 被设计用来使用短链接，即每次发送数据都会经过 TCP 的三次握手和四次挥手，效率比较低。

HTTP 1.0 只使用 header 中的 If-Modified-Since 和 Expires 作为缓存失效的标准。

HTTP 1.0 不支持断点续传，也就是说，每次都会传送全部的页面和数据。

HTTP 1.0 认为每台计算机只能绑定一个 IP，所以请求消息中的 URL 并没有传递主机名（hostname）。

\-----------------------------------------------------------------------------------------------------------------

HTTP 1.1 使用了摘要算法来进行身份验证

HTTP 1.1 默认使用长连接，长连接就是只需一次建立就可以传输多次数据，传输完成后，只需要一次切断连接即可。长连接的连接时长可以通过请求头中的 keep-alive 来设置

HTTP 1.1 中新增加了 E-tag，If-Unmodified-Since, If-Match, If-None-Match 等缓存控制标头来控制缓存失效。

HTTP 1.1 支持断点续传，通过使用请求头中的 Range 来实现。

HTTP 1.1 使用了虚拟网络，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。

\------------------------------------------------------------------------------------------------------------------

头部压缩，由于 HTTP 1.1 经常会出现 User-Agent、Cookie、Accept、Server、Range 等字段可能会占用几百甚至几千字节，而 Body 却经常只有几十字节，所以导致头部偏重。HTTP 2.0 使用 HPACK 算法进行压缩。

二进制格式，HTTP 2.0 使用了更加靠近 TCP/IP 的二进制格式，而抛弃了 ASCII 码，提升了解析效率

强化安全，由于安全已经成为重中之重，所以 HTTP2.0 一般都跑在 HTTPS 上。

多路复用，即每一个请求都是用作连接共享。一个请求对应一个id，这样一个连接上可以有多个请求。



#### 6.HTTP的常见状态码有哪些，代表什么含义？比如200, 302, 404？

![img](https://cdn.nlark.com/yuque/0/2021/png/754871/1620464951008-a6117a01-8a6a-40f6-a12f-88a05b9f5cec.png)

200 OK：请求已正常处理。

302 Found：资源的URI已临时定位到其他位置了，姑且算你已经知道了这个情况了。临时性重定向。和301相似，但302代表的资源不是永久性移动，只是临时性性质的。换句话说，已移动的资源对应的URI将来还有可能发生改变。

404 Not Found：服务器上没有请求的资源。路径错误等。

https://blog.csdn.net/qq_35689573/article/details/82120851

https://blog.csdn.net/qq_40806970/article/details/105870996



#### 7.当你用浏览器打开一个链接到返回结果，发生了什么。

![img](https://cdn.nlark.com/yuque/0/2021/webp/754871/1620465281837-24c7dfc1-d99d-461c-93c4-9e968e74c279.webp)

DNS解析

TCP连接

发送HTTP请求

服务器处理请求并返回HTTP报文

浏览器解析渲染页面

连接结束

https://segmentfault.com/a/1190000006879700

https://mp.weixin.qq.com/s/I6BLwbIpfGEJnxjDcPXc1A



#### 8.TCP/IP如何保证可靠性，说说TCP头的结构。

应用数据被分割成 TCP 认为最适合发送的数据块。

TCP 给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。

校验和： TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。

TCP 的接收端会丢弃重复的数据。

流量控制： TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制）

拥塞控制： 当网络拥塞时，减少数据的发送。

ARQ协议： 也是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。

超时重传： 当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。

![img](https://cdn.nlark.com/yuque/0/2021/png/754871/1620466162450-304e1db2-97d4-4d47-b0c4-623b1142fed5.png)

https://blog.csdn.net/liuchenxia8/article/details/80428157



#### 9.GET与POST方式的区别

get 方法一般用于请求，比如你在浏览器地址栏输入 www.cxuanblog.com 其实就是发送了一个 get 请求，它的主要特征是请求服务器返回资源

post 方法一般用于表单的提交，相当于是把信息提交给服务器，等待服务器作出响应，get 相当于一个是 pull/拉的操作，而 post 相当于是一个 push/推的操作。

get 方法是不安全的，因为你在发送请求的过程中，你的请求参数会拼在 URL 后面，从而导致容易被攻击者窃取，对你的信息造成破坏和伪造；

/test/demo_form.asp?name1=value1&name2=value2

而 post 方法是把参数放在请求体 body 中的，这对用户来说不可见。

POST /test/demo_form.asp HTTP/1.1

Host: w3schools.com

name1=value1&name2=value2

get 请求的 URL 有长度限制，而 post 请求会把参数和值放在消息体中，对数据长度没有要求。

get 请求会被浏览器主动 cache，而 post 不会，除非手动设置。

get 请求在浏览器反复的 回退/前进 操作是无害的，而 post 操作会再次提交表单请求。

get 请求在发送过程中会产生一个 TCP 数据包；post 在发送过程中会产生两个 TCP 数据包。对于 get 方式的请求，浏览器会把 http header 和 data 一并发送出去，服务器响应 200（返回数据）；而对于 post，浏览器先发送 header，服务器响应 100 continue，浏览器再发送 data，服务器响应 200 ok（返回数据）。



#### 10.如何避免浏览器缓存。

HTTP 信息头中包含 Cache-Control:no-cache，pragma:no-cache，或 Cache-Control:max-age=0 等告诉浏览器不用缓存的请求

需要根据 Cookie，认证信息等决定输入内容的动态请求是不能被缓存的

经过 HTTPS 安全加密的请求（有人也经过测试发现，ie 其实在头部加入 Cache-Control：max-age 信息，firefox 在头部加入 Cache-Control:Public 之后，能够对 HTTPS 的资源进行缓存，参考《HTTPS 的七个误解》）

POST 请求无法被缓存

HTTP 响应头中不包含 Last-Modified/Etag，也不包含 Cache-Control/Expires 的请求无法被缓存

https://blog.csdn.net/xdhc304/article/details/86982281



#### 11.TCP/IP模型?

https://mp.weixin.qq.com/s/lkX2Mb2aCj8ugOaRmVVBqw

七层网络模型

物理层

数据链路层

网络层

传输层

会话层

表示层

应用层



#### 12.讲一讲 TCP 和 UDP 各有什么特点，两者有什么区别

**1. 连接**

TCP 是面向连接的传输层协议，传输数据前先要建立连接。

UDP 是不需要连接，即刻传输数据。

**2. 服务对象**

TCP 是一对一的两点服务，即一条连接只有两个端点。

UDP 支持一对一、一对多、多对多的交互通信

**3. 可靠性**

TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按需到达。

UDP 是尽最大努力交付，不保证可靠交付数据。

**4. 拥塞控制、流量控制**

TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。

UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。

**5. 首部开销**

TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使用了「选项」字段则会变长的。

UDP 首部只有 8 个字节，并且是固定不变的，开销较小。                                                                                                                                                                                                                                                                                                                 

![img](https://cdn.nlark.com/yuque/0/2021/png/754871/1620479212841-46ac0b87-f997-41a8-8148-dcd2d699c86a.png)

#### 13.详细讲一下TCP的滑动窗口

窗口大小就是指无需等待确认应答而可以继续发送数据的最大值。

这个机制实现了使用大量的缓冲区"，通过对多个段同时进行确认应答的功能。

缓冲区(Bulter) 在此处表示临时保存收发数据的场所。通常是在计算机内存中开辟的部分空间。

如图6.16所示，发送数据中高亮圈起的部分正是前面所提到的窗口。在这个窗口内的数据即便没有收到确认应答也可以发送出去。此外，从该窗口中能看到的数据因其某种数据已在传输中丢失，所以发送端才能收到确认应答，这种情况也需进行重发。为此，发送端主机在等到确认应答返回之前，必须在缓冲区中保留这部分数据。

在滑动窗口以外的部分包括尚未发送的数据以及已经确认对端已收到的数据。当数据发出后若如期收到确认应答就可以不用再进行重发，此时数据就可以从缓存区清除。收到确认应答的情况下，将窗口滑动到确认应答中的序列号的位置。这样可以顺序地将多个段同时发送提高通信性能。这种机制也被称为滑动窗口控制。

![img](https://cdn.nlark.com/yuque/0/2021/png/754871/1620546839000-fdfa1fb3-4bad-474d-a40e-490369e2f58c.png)

#### 说一下拥塞控制

慢启动

拥塞避免

快重传

快恢复

**慢启动**

TCP 在刚建立连接完成后，首先是有个慢启动的过程，这个慢启动的意思就是一点一点的提高发送数据包的数量，如果一上来就发大量的数据，这不是给网络添堵吗？

慢启动的算法记住一个规则就行：当发送方每收到一个 ACK，就拥塞窗口 cwnd 的大小就会加 1。

这里假定拥塞窗口 cwnd 和发送窗口 swnd 相等，下面举个栗子：

连接建立完成后，一开始初始化 cwnd = 1，表示可以传一个 MSS 大小的数据。

当收到一个 ACK 确认应答后，cwnd 增加 1，于是一次能够发送 2 个

当收到 2 个的 ACK 确认应答后， cwnd 增加 2，于是就可以比之前多发2 个，所以这一次能够发送 4 个

当这 4 个的 ACK 确认到来的时候，每个确认 cwnd 增加 1， 4 个确认 cwnd 增加 4，于是就可以比之前多发 4 个，所以这一次能够发送 8 个。

![img](https://cdn.nlark.com/yuque/0/2021/png/754871/1620550752529-79c9a999-62fe-4bb8-90c5-d470dac2da52.png)



有一个叫慢启动门限  ssthresh （slow start threshold）状态变量。

当 cwnd < ssthresh 时，使用慢启动算法。

当 cwnd >= ssthresh 时，就会使用「拥塞避免算法」。



**拥塞避免算法**

前面说道，当拥塞窗口 cwnd 「超过」慢启动门限 ssthresh 就会进入拥塞避免算法。

一般来说 ssthresh 的大小是 65535 字节。

那么进入拥塞避免算法后，它的规则是：每当收到一个 ACK 时，cwnd 增加 1/cwnd。

接上前面的慢启动的栗子，现假定 ssthresh 为 8：

当 8 个 ACK 应答确认到来时，每个确认增加 1/8，8 个 ACK 确认 cwnd 一共增加 1，于是这一次能够发送 9 个 MSS 大小的数据，变成了线性增长。

![img](https://cdn.nlark.com/yuque/0/2021/png/754871/1620550940661-4e80d4f3-6931-48eb-9ab7-e68c4832f60b.png)

拥塞避免

所以，我们可以发现，拥塞避免算法就是将原本慢启动算法的指数增长变成了线性增长，还是增长阶段，但是增长速度缓慢了一些。

就这么一直增长着后，网络就会慢慢进入了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进行重传。

当触发了重传机制，也就进入了「拥塞发生算法」。



当发生了**「超时重传」**，则就会使用拥塞发生算法。

这个时候，sshresh 和 cwnd 的值会发生变化：

ssthresh 设为 cwnd/2，

cwnd 重置为 1

![img](https://cdn.nlark.com/yuque/0/2021/png/754871/1620551173089-86568723-c516-498c-903a-82a5aa9a7dca.png)

拥塞发送 —— 超时重传

接着，就重新开始慢启动，慢启动是会突然减少数据流的。



**快速重传算法**」。当接收方发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传。

TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则 ssthresh 和 cwnd 变化如下：

cwnd = cwnd/2 ，也就是设置为原来的一半;

ssthresh = cwnd;

进入快速恢复算法



**快速恢复**

快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像 RTO 超时那么强烈。

正如前面所说，进入快速恢复之前，cwnd 和 ssthresh 已被更新了：

cwnd = cwnd/2 ，也就是设置为原来的一半;

ssthresh = cwnd;

然后，进入快速恢复算法如下：

拥塞窗口 cwnd = ssthresh + 3 （ 3 的意思是确认有 3 个数据包被收到了）

重传丢失的数据包

如果再收到重复的 ACK，那么 cwnd 增加 1

如果收到新数据的 ACK 后，设置 cwnd 为 ssthresh，接着就进入了拥塞避免算法

![img](https://cdn.nlark.com/yuque/0/2021/png/754871/1620551550248-e0f769f5-96d3-4dcb-bb3f-62c2481fd1bd.png)

也就是没有像「超时重传」一夜回到解放前，而是还在比较高的值，后续呈线性增长。

![img](https://cdn.nlark.com/yuque/0/2021/png/754871/1620551679504-c78be6ec-ba34-4e7a-a2db-3451450aaf99.png)

#### 14.如何理解HTTP协议的无状态性。

无状态协议(Stateless Protocol) 就是指浏览器对于事务的处理没有记忆能力。举个例子来说就是比如客户请求获得网页之后关闭浏览器，然后再次启动浏览器，登录该网站，但是服务器并不知道客户关闭了一次浏览器。

HTTP 就是一种无状态的协议，他对用户的操作没有记忆能力。可能大多数用户不相信，他可能觉得每次输入用户名和密码登陆一个网站后，下次登陆就不再重新输入用户名和密码了。这其实不是 HTTP 做的事情，起作用的是一个叫做 小甜饼(Cookie) 的机制。它能够让浏览器具有记忆能力。



#### HTTP有哪些 method？

![img](https://cdn.nlark.com/yuque/0/2021/png/754871/1620479292204-45d27938-558f-4a57-838e-d406257c6b53.png)



#### 15.HTTP长连接和短连接

在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个HTML或其他类型的Web页中包含有其他的Web资源（如JavaScript文件、图像文件、CSS文件等），每遇到这样一个Web资源，浏览器就会重新建立一个HTTP会话。

而从HTTP/1.1起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头加入这行代码：

Connection:keep-alive

在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。

**HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接**

https://www.cnblogs.com/gotodsp/p/6366163.html

#### 16.HTTPS原理，加签，验签，什么是数字签名？什么是数字证书？对称加密和非对称加密等。

![img](https://cdn.nlark.com/yuque/0/2021/webp/754871/1620479812510-e5be30b3-5f17-48b5-9b1a-5fff57d059a7.webp)

用户在浏览器发起HTTPS请求（如 https://www.mogu.com/），默认使用服务端的443端口进行连接；

HTTPS需要使用一套CA数字证书，证书内会附带一个公钥Pub，而与之对应的私钥Private保留在服务端不公开；

服务端收到请求，返回配置好的包含公钥Pub的证书给客户端；

客户端收到证书，校验合法性，主要包括是否在有效期内、证书的域名与请求的域名是否匹配，上一级证书是否有效（递归判断，直到判断到系统内置或浏览器配置好的根证书），如果不通过，则显示HTTPS警告信息，如果通过则继续；

客户端生成一个用于对称加密的随机Key，并用证书内的公钥Pub进行加密，发送给服务端；

服务端收到随机Key的密文，使用与公钥Pub配对的私钥Private进行解密，得到客户端真正想发送的随机Key；

服务端使用客户端发送过来的随机Key对要传输的HTTP数据进行对称加密，将密文返回客户端；

客户端使用随机Key对称解密密文，得到HTTP数据明文；

后续HTTPS请求使用之前交换好的随机Key进行对称加解密。



为什么要用CA：

考虑中间人攻击的情况，非对称加密的算法都是公开的，所有人都可以自己生成一对公钥私钥。

客户端无法确认收到的公钥是不是真的是服务端发来的

私钥除了解密外的真正用途其实还有一个，就是数字签名



HTTPS 的出发点是解决HTTP明文传输时信息被篡改和监听的问题。

为了兼顾性能和安全性，使用了非对称加密+对称加密的方案。

为了保证公钥传输中不被篡改，又使用了非对称加密的数字签名功能，借助CA机构和系统根证书的机制保证了HTTPS证书的公信力。

https://mp.weixin.qq.com/s/21JaXwdfSjItj5SgOwhapg



#### 17.谈下你对 IP 地址分类的理解？

IP地址类型

   最初设计互联网络时，为了便于寻址以及层次化构造网络，每个IP地址包括两个标识码（ID），即网络ID和主机ID。同一个物理网络上的所有主机都使用同一个网络ID，网络上的一个主机（包括网络上工作站，服务器和路由器等）有一个主机ID与其对应。IP地址根据网络ID的不同分为5种类型，A类地址、B类地址、C类地址、D类地址和E类地址。


![img](https://cdn.nlark.com/yuque/0/2021/png/754871/1620551961326-4bbdb71b-adb6-4c2b-a162-8424e7e8ad1d.png)



#### 18.ARP及RARP协议的工作原理？

ARP协议是用于由节点IP地址解析其MAC地址

（1）每台主机都会根据以往在网络中与其他节点的通信，在自己的ARP缓存区（ARP Cache）中建立一个ARP列表，以表示网络中节点IP地址和MAC地址的对应关系。

【说明】ARP缓存表采用了老化机制，在一段时间内如果表中的某一行没有使用（Windows系统的这个时间为2分钟，而Cisco路由器的这个时间为5分钟），就会被删除，这样可以大大减少ARP缓存表的长度，加快查询速度。

（2）当源节点需要将一个数据包发送到目标节点时，会首先检查自己ARP列表中是否存在该包中所包含的目标节点IP地址对应的MAC地址。如果有，则直接将数据包发送到这个MAC地址节点上；如果没有，就向本地网段发起一个ARP请求的广播包，查询此IP地址目标节点对应的MAC地址。此ARP请求数据包里包括源节点的IP地址、硬件地址，以及目标节点的IP地址。

（3）网络中所有的节点在收到这个ARP请求后，会检查数据包中的目标IP地址是否和自己的IP地址一致。如果不相同就忽略此数据包；如果相同，该节点首先将源端的MAC地址和IP地址的对应表项添加到自己的ARP列表中。如果发现ARP表中已经存在该IP地址所对应的MAC地址表项信息，则将其覆盖，然后给源节点发送一个ARP响应数据包，告诉对方自己是它需要查找的MAC地址节点。

（4）源节点在收到这个ARP响应数据包后，将得到的目标节点的IP地址和MAC地址对应表项添加到自己的ARP列表中，并利用此信息开始数据的传输。如果源节点一直没有收到ARP响应数据包，则表示ARP查询失败。



RARP则是根据MAC地址找其对应IP地址

（1）发送端发送一个本地的RARP广播包，在此广播包中声明自己的MAC地址，并且请求任何收到此请求的RARP服务器分配一个IP地址。

（2）本地网段上的RARP服务器收到此请求后，检查其RARP列表，查找该MAC地址对应的IP地址。如果存在，RARP服务器就给源主机发送一个响应数据包，并将此IP地址提供给对方主机使用；如果不存在，RARP服务器对此不做任何响应。

（3）源端在收到从RARP服务器来的响应信息后，利用得到的IP地址进行通信；如果一直没有收到RARP服务器的响应信息，则表示初始化失败。

https://blog.csdn.net/x_i_y_u_e/article/details/50953132



#### 19.怎么解决拆包和粘包？

因为TCP是面向流，没有边界，而操作系统在发送TCP数据时，会通过缓冲区来进行优化，例如缓冲区为1024个字节大小。

如果一次请求发送的数据量比较小，没达到缓冲区大小，TCP则会将多个请求合并为同一个请求进行发送，这就形成了粘包问题。

如果一次请求发送的数据量比较大，超过了缓冲区大小，TCP就会将其拆分为多次发送，这就是拆包。

对于粘包和拆包问题，常见的解决方案有四种：

发送端将每个包都封装成固定的长度，比如100字节大小。如果不足100字节可通过补0或空等进行填充到指定长度；

发送端在每个包的末尾使用固定的分隔符，例如\r\n。如果发生拆包需等待多个包发送过来之后再找到其中的\r\n进行合并；例如，FTP协议；

将消息分为头部和消息体，头部中保存整个消息的长度，只有读取到足够长度的消息之后才算是读到了一个完整的消息；

通过自定义协议进行粘包和拆包的处理。



#### 20.DNS 的解析过程？

一、主机向本地域名服务器的查询一般都是采用递归查询。所谓递归查询就是：如果主机所询问的本地域名服务器不知道被查询的域名的IP地址，那么本地域名服务器就以DNS客户的身份，向其它根域名服务器继续发出查询请求报文(即替主机继续查询)，而不是让主机自己进行下一步查询。因此，递归查询返回的查询结果或者是所要查询的IP地址，或者是报错，表示无法查询到所需的IP地址。

二、本地域名服务器向根域名服务器的查询的迭代查询。迭代查询的特点：当根域名服务器收到本地域名服务器发出的迭代查询请求报文时，要么给出所要查询的IP地址，要么告诉本地服务器：“你下一步应当向哪一个域名服务器进行查询”。然后让本地服务器进行后续的查询。根域名服务器通常是把自己知道的顶级域名服务器的IP地址告诉本地域名服务器，让本地域名服务器再向顶级域名服务器查询。顶级域名服务器在收到本地域名服务器的查询请求后，要么给出所要查询的IP地址，要么告诉本地服务器下一步应当向哪一个权限域名服务器进行查询。最后，知道了所要解析的IP地址或报错，然后把这个结果返回给发起查询的主机。

下图给出了这两种查询的差别

![img](https://cdn.nlark.com/yuque/0/2021/png/754871/1620481390690-e1d6246a-28e5-4c57-b30d-103e00b6112c.png)

​     下面举一个例子演示整个查询过程：

假定域名为m.xyz.com的主机想知道另一个主机y.abc.com的IP地址。例如，主机m.xyz.com打算发送邮件给y.abc.com。这时就必须知道主机y.abc.com的IP地址。

下面是上图a的几个查询步骤：

1、主机m.abc.com先向本地服务器dns.xyz.com进行递归查询。

2、本地服务器采用迭代查询。它先向一个根域名服务器查询。

3、根域名服务器告诉本地服务器，下一次应查询的顶级域名服务器dns.com的IP地址。

4、本地域名服务器向顶级域名服务器dns.com进行查询。

5、顶级域名服务器dns.com告诉本地域名服务器，下一步应查询的权限服务器dns.abc.com的IP地址。

6、本地域名服务器向权限域名服务器dns.abc.com进行查询。

7、权限域名服务器dns.abc.com告诉本地域名服务器，所查询的主机的IP地址。

8、本地域名服务器最后把查询结果告诉m.xyz.com。

https://blog.csdn.net/yipiankongbai/article/details/25031461



#### 21.什么是DoS、DDoS、DRDoS攻击？如何防御？

 DoS(Denial of Service，拒绝服务攻击)，它的原理很简单，就是用我们手里的机器去给服务器发请求，如果我们手头的服务器各方面性能都比服务器的主机的性能好，那么当我们发送大量请求给服务器，占用服务器的资源，导致服务器没有能力去处理其他用户请求。

第一种方法，缩短等待时间，尽早删除在等待队列中等待非法请求数据包；

第二种方法是在第一次握手报文不放入等待队列，我们将一个32位的无符号整数作为第二次握手的Seq返回给客户端，该整数通过将用户请求的参数（包括请求的地址、端口等），加上服务器的一个序列号等做了一次运算得到。如果是正常用户，它在收到这个整数之后加1作为ACK返回给服务器，服务器在拿到数据后，对这个ACK减1再进行逆运算得到各个参数，最后发出去的数据进行比对，如果完全一致，说明是一个有效的响应，存放到相应的数据结构，反之则不是。通过该方法，非法请求就不能占用系统资源了。



DDoS(Distributed Denial of Service，分布式拒绝服务)，它是DoS家族里很难防范的一种攻击方式，攻击者首先控制大量肉鸡，然后向目标服务器发送海量请求，导致目标服务器不可用。这里我们不禁要问攻击者是如何获取大量肉鸡的呢？攻击者会对某些APP或网站植入一些恶意代码，譬如说curl www.mukedada.com，用户在使用这款APP或网站时，会自动请求www.mukedada.com这个网站，如果这款APP或网站的活跃用户数很多，那么这个网站就会受到很多莫名的请求。这就要求我们在平时上网过程中不要浏览一些不知名的网站和下载来源不明的APP。



DRDoS((Distributed Reflection Denial of Service，分布式反射拒绝服务)，攻击者将不是将请求直接发送给被攻击者，而是发送给一个第三方，通过第三方中转到被攻击者，这就是"Reflection"的体现。它的流程具体如下：攻击者将请求包的源IP篡改成要被攻击者的IP，目标IP是第三方IP，那么第三方的恢复报文的目标IP就变成被攻击者的IP，这样一来，被攻击者就会收到大量请求导致服务不可用。

https://blog.csdn.net/wenjianfeng/article/details/90096514



#### 22.WebSocket与socket的区别

Socket本意大致是指在端到端的一个连接中，这两个端叫做Socket。

https://www.jianshu.com/p/59b5594ffbb0

#### 23.讲一讲SYN超时，洪泛攻击，以及解决策略

也就是 client 发送 SYN 至 server 然后就挂了，此时 server 发送 SYN+ACK 就一直得不到回复，怎么办？

第一想到的就是重试，但是不能连续快速重试多次，你想一下，假设 client 掉线了，你总得给它点时间恢复吧，所以呢需要慢慢重试，阶梯性重试。

在 Linux 中就是默认重试 5 次，并且就是阶梯性的重试，间隔就是1s、2s、4s、8s、16s，再第五次发出之后还得等 32s 才能知道这次重试的结果，所以说总共等63s 才能断开连接。



什么 SYN 是洪泛攻击？ 在 TCP 的三次握手机制的第一步中，客户端会向服务器发送 SYN 报文段。服务器接收到 SYN 报文段后会为该TCP分配缓存和变量，如果攻击分子大量地往服务器发送 SYN 报文段，服务器的连接资源终将被耗尽，导致内存溢出无法继续服务。



解决策略：

当服务器接受到 SYN 报文段时，不直接为该 TCP 分配资源，而只是打开一个半开的套接字。接着会使用 SYN 报文段的源Id，目的Id，端口号以及只有服务器自己知道的一个秘密函数生成一个 cookie，并把 cookie 作为序列号响应给客户端。

如果客户端是正常建立连接，将会返回一个确认字段为 cookie + 1 的报文段。接下来服务器会根据确认报文的源Id，目的Id，端口号以及秘密函数计算出一个结果，如果结果的值 + 1等于确认字段的值，则证明是刚刚请求连接的客户端，这时候才为该 TCP 分配资源这样一来就不会为恶意攻击的 SYN 报文段分配资源空间，避免了攻击。



可以开启 tcp_syncookies，那就用不到 SYN 队列了。

SYN 队列满了之后 TCP 根据自己的 ip、端口、然后对方的 ip、端口，对方 SYN 的序号，时间戳等一波操作生成一个特殊的序号（即 cookie）发回去，如果对方是正常的 client 会把这个序号发回来，然后 server 根据这个序号建连。

或者调整 tcp_synack_retries 减少重试的次数，设置 tcp_max_syn_backlog 增加 SYN 队列数，设置 tcp_abort_on_overflow SYN 队列满了直接拒绝连接。



#### 24.ICMP协议的功能（ping的原理）

ICMP 主要的功能包括：确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。



#### 25.什么是 session，有哪些实现 session 的机制？

服务器为了保存用户状态而创建的一个特殊的对象。

当浏览器第一次访问服务器时，服务器创建一个session对象(该对象有一个唯一的id,一般称之为sessionId),服务器会将sessionId以cookie的方式发送给浏览器。

当浏览器再次访问服务器时，会将sessionId发送过来，服务器依据sessionId就可以找到对应的session对象。



一般用来实现Session的方法有两种：

（1）URL重写。

Web Server在返回Response的时候，检查页面中所有的URL，包括所有的连接，和HTML Form的Action属性，在这些URL后面加上“;jsessionid=XXX”。

下一次，用户访问这个页面中的URL。jsessionid就会传回到Web Server。

（2）Cookie。

如果客户端支持Cookie，Web Server在返回Response的时候，在Response的Header部分，加入一个“set-cookie: jsessionid=XXXX”header属性，把jsessionid放在Cookie里传到客户端。

客户端会把Cookie存放在本地文件里，下一次访问Web Server的时候，再把Cookie的信息放到HTTP Request的“Cookie”header属性里面，这样jsessionid就随着HTTP Request返回给Web Server。



#### 26.Http请求的过程与原理

域名解析 --> 发起TCP的3次握手 --> 建立TCP连接后发起http请求 --> 服务器响应http请求，浏览器得到html代码 --> 浏览器解析html代码，并请求html代码中的资源（如js、css、图片等） --> 浏览器对页面进行渲染呈现给用户

https://www.cnblogs.com/engeng/articles/5959335.html

https://mp.weixin.qq.com/s/21JaXwdfSjItj5SgOwhapg

#### 27.你知道网络协议有那些？

TCP/IP协议、HTTP协议、FTP协议、Telnet协议、SMTP协议、UDP协议等。

#### 28.HTTPS 为什么是安全的？说一下他的底层实现原理？

1. 混合加密的方式实现信息的机密性，解决了窃听的风险。
2. 摘要算法的方式来实现完整性，它能够为数据生成独一无二的「指纹!，指纹用于校验数据的完整性解决了篡改的风险。
3. 将服务器公钥放入到数字证书中，解决了冒充的风险。

CA证书，数字签名，非对称加密，对称加密

#### 29.ping的原理

ping 是基于 ICMP（互联网控制报文协议） 协议工作

ping 命令执行的时候，源主机首先会构建一个 ICMP 回送请求消息数据包。

ICMP 数据包内包含多个字段，最重要的是两个：

- 第一个是类型，对于回送请求消息而言该字段为 `8`；
- 另外一个是序号，主要用于区分连续 ping 的时候发出的多个数据包。

每发出一个请求数据包，序号会自动加 `1`。为了能够计算往返时间 `RTT`，它会在报文的数据部分插入发送时间。

![img](https://cdn.nlark.com/yuque/0/2021/png/754871/1620561750054-b0699e64-7ba6-4f2c-b352-c778c542f0be.png)

然后，由 ICMP 协议将这个数据包连同地址 192.168.1.2 一起交给 IP 层。IP 层将以 192.168.1.2 作为目的地址，本机 IP 地址作为源地址，协议字段设置为 `1` 表示是 `ICMP` 协议，在加上一些其他控制信息，构建一个 `IP` 数据包。

![img](https://cdn.nlark.com/yuque/0/2021/webp/754871/1620561750056-04b2b914-d8fd-4597-a86f-61c93107848d.webp)

接下来，需要加入 `MAC` 头。如果在本地 ARP 映射表中查找出 IP 地址 192.168.1.2 所对应的 MAC 地址，则可以直接使用；如果没有，则需要发送 `ARP` 协议查询 MAC 地址，获得 MAC 地址后，由数据链路层构建一个数据帧，目的地址是 IP 层传过来的 MAC 地址，源地址则是本机的 MAC 地址；还要附加上一些控制信息，依据以太网的介质访问规则，将它们传送出去。

![img](https://cdn.nlark.com/yuque/0/2021/webp/754871/1620561750211-4b251df9-39e9-433c-8689-cea037b7359f.webp)

主机 A 的 MAC 层数据包

主机 `B` 收到这个数据帧后，先检查它的目的 MAC 地址，并和本机的 MAC 地址对比，如符合，则接收，否则就丢弃。

接收后检查该数据帧，将 IP 数据包从帧中提取出来，交给本机的 IP 层。同样，IP 层检查后，将有用的信息提取后交给 ICMP 协议。

主机 `B` 会构建一个 ICMP 回送响应消息数据包，回送响应数据包的类型字段为 `0`，序号为接收到的请求数据包中的序号，然后再发送出去给主机 A。

![img](https://cdn.nlark.com/yuque/0/2021/png/754871/1620561750153-cd60bf0c-e0ba-4cc4-8255-e1f1a6a90a35.png)主机 B 的 ICMP 回送响应报文

在规定的时候间内，源主机如果没有接到 ICMP 的应答包，则说明目标主机不可达；如果接收到了 ICMP 回送响应消息，则说明目标主机可达。

此时，源主机会检查，用当前时刻减去该数据包最初从源主机上发出的时刻，就是 ICMP 数据包的时间延迟。

针对上面发生的事情，总结成了如下图：

![img](https://cdn.nlark.com/yuque/0/2021/webp/754871/1620561749989-2b3b9065-cd73-4d30-8639-7d826b4b8221.webp)主机 A ping 主机 B 期间发送的事情

当然这只是最简单的，同一个局域网里面的情况。如果跨网段的话，还会涉及网关的转发、路由器的转发等等。

但是对于 ICMP 的头来讲，是没什么影响的。会影响的是根据目标 IP 地址，选择路由的下一跳，还有每经过一个路由器到达一个新的局域网，需要换 MAC 头里面的 MAC 地址。

说了这么多，可以看出 ping 这个程序是使用了 ICMP 里面的 ECHO REQUEST（类型为 8 ） 和 ECHO REPLY （类型为 0）。



https://mp.weixin.qq.com/s/3KF0IxLum8EOtcF0ZNIiPA

#### 30.如果服务器出现了大量 CLOSE_WAIT 状态如何解决。

一直保持在CLOSE_WAIT状态，那么只有一种情况，就是在对方关闭连接之后服务器程序自己没有进一步发出ack信号。换句话说，就是在对方连接关闭之后，程序里没有检测到，或者程序压根就忘记了这个时候需要关闭连接，于是这个资源就一直被程序占着。个人觉得这种情况，通过服务器内核参数也没办法解决，服务器对于程序抢占的资源没有主动回收的权利，除非终止程序运行。



#### 31.TCP 粘包是怎么产生的？

TCP网络传输的应用程序有时会出现粘包现象，因为tcp传输没有消息边界，发送方发送若干次数据的时候，数据粘连在一起，接收方一次性将发送方多次发送的数据一起接收，产生接收数据的粘连。

https://blog.csdn.net/weixin_43793181/article/details/109153975

https://blog.csdn.net/meism5/article/details/90414255

#### 32.OSI七层体系结构

应用层

表示层

会话层

运输层

网络层.

数据链路层

物理层

#### 33.路由器与交换机的区别

 路由器在网络层，路由器根据IP地址寻址，路由器可以处理TCP/IP协议，交换机不可以。交换机数据链路层，交换机根据MAC地址寻址。

#### 34.什么是XSS攻击，如何避免

XSS 攻击，即跨站脚本攻击（Cross Site Scripting），它是 web 程序中常见的漏洞。

攻击者往 web 页面里插入恶意的 HTML 代码（Javascript、css、html 标签等），当用户浏览该页面时，嵌入其中的 HTML 代码会被执行，从而达到恶意攻击用户的目的。如盗取用户 cookie 执行一系列操作，破坏页面结构、重定向到其他网站等。 

预防思路  

web 页面中可由用户输入的地方，如果对输入的数据转义、过滤处理

后台输出页面的时候，也需要对输出内容进行转义、过滤处理（因为攻击者可能通过其他方式把恶意脚本写入数据库）

前端对 html 标签属性、css 属性赋值的地方进行校验

#### 35.什么是CSRF攻击，如何避免

 CSRF：Cross Site Request Forgery（跨站点请求伪造）。

CSRF 攻击者在用户已经登录目标网站之后，诱使用户访问一个攻击页面，利用目标网站对用户的信任，以用户身份在攻击页面对目标网站发起伪造用户操作的请求，达到攻击目的。



避免方法：

CSRF 漏洞进行检测的工具，如 CSRFTester、CSRF Request Builder...

验证 HTTP Referer 字段

添加并验证 token

添加自定义 http 请求头

敏感操作添加验证码

使用 post 请求

 

#### 36.Https双向和单向验证的区别

双向认证

  1、先决条件是有两个或两个以上的证书，一个是服务端证书，另一个或多个是客户端证书。

  2、服务端保存着客户端的证书并信任该证书，客户端保存着服务端的证书并信任该证书。这样，在证书验证成功的情况下即可完成请求响应。

  3、双向认证一般企业应用对接。

单向认证

  1、客户端保存着服务端的证书并信任该证书即可

  2、https一般是单向认证，这样可以让绝大部分人都可以访问你的站点。



#### 37.如果客户端禁止Cookie能实现Session

一般默认情况下，在会话中，服务器存储 session 的 sessionid 是通过 cookie 存到浏览器里。

如果浏览器禁用了 cookie，浏览器请求服务器无法携带 sessionid，服务器无法识别请求中的用户身份，session失效。

但是可以通过其他方法在禁用 cookie 的情况下，可以继续使用session。

通过url重写，把 sessionid 作为参数追加的原 url 中，后续的浏览器与服务器交互中携带 sessionid 参数。

服务器的返回数据中包含 sessionid，浏览器发送请求时，携带 sessionid 参数。

通过 Http 协议其他 header 字段，服务器每次返回时设置该 header 字段信息，浏览器中 js 读取该 header 字段，请求服务器时，js设置携带该 header 字段。





#### 38.HTTP请求中session实现原理

HTTP协议是无状态的，Session不能依据HTTP连接来判断是否为同一个用户。于是乎：服务器向用户浏览器发送了一个名为JESSIONID的Cookie，它的值是Session的id值。其实Session是依据Cookie来识别是否是同一个用户。

https://mp.weixin.qq.com/s/drPVkRbCsDIlX6Ls2pDmqA

https://mp.weixin.qq.com/s/LUtk6u_zv0w8g8GIGWEuCw

**应用层(application-layer）**的任务是通过应用进程间的交互来完成特定网络应用。

在互联网中应用层协议很多，如域名系统DNS，支持万维网应用的 HTTP协议，支持电子邮件的 SMTP协议等等。我们把应用层交互的数据单元称为报文。

**运输层(transport layer)**的主要任务就是负责向两台主机进程之间的通信提供通用的数据传输服务。

运输层主要使用以下两种协议:

传输控制协议 TCP（Transmission Control Protocol）--提供面向连接的，可靠的数据传输服务。

用户数据协议 UDP（User Datagram Protocol）--提供无连接的，尽最大努力的数据传输服务（不保证数据传输的可靠性）。

**网络层**的任务就是选择合适的网间路由和交换结点， 确保数据及时传送。 在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组和包进行传送。在 TCP/IP 体系结构中，由于网络层使用 IP 协议，因此分组也叫 IP 数据报 ，简称 数据报。

**数据链路****层(data link layer)**通常简称为链路层。两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层的协议。 在两个相邻节点之间传送数据时，数据链路层将网络层交下来的 IP 数据报组装成帧

**物理层(physical layer)**的作用是实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异，

![img](https://cdn.nlark.com/yuque/0/2021/png/754871/1620569965371-538e704f-8fa6-42f9-b8aa-791ca061f329.png)

# 复习重点：

OSI 模型、TCP/IP 模型

TCP 和 UDP 区别

TCP 可靠性传输原理：重传、流量控制、拥塞控制、序列号与确认应达号、校验和

三次握手、四次挥手过程、原理

timewait、closewait

HTTP

报文格式

1.0 1.1 2.0

状态码

无状态解决（Cookie Session 原理）

HTTPS

CA 证书

对称加密

非对称加密

DNS 解析过程，原理

IP 协议、ICMP 协议（Ping、Tracert）、ARP 协议、路由协议

攻击手段与防范：XSS、CSRF、SQL 注入、DOS、DDOS



[图解TCP IP第5版.pdf](https://www.yuque.com/attachments/yuque/0/2025/pdf/40453232/1748423593290-edbe9f98-6c6d-4587-b2e7-da6220cff725.pdf)