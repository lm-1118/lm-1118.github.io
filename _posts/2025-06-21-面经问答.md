
---
title: 场景题面经
date: 2025-06-21 10:00:00 +0800
categories: [面试经验, Go]
tags: [golang, 学习笔记, 面试相关]
---

### 我现在有1万个问答请求，但服务器只能同时容纳1000个请求，你怎么做
1. 限流（Rate Limiting）
防止服务器过载，确保核心服务稳定
使用 令牌桶（Token Bucket） 或 漏桶（Leaky Bucket） 算法，限制 QPS（每秒请求数）。
如果超出并发上限, 返回 429（请求过多），让客户端稍后重试。
可以使用 Nginx、Traefik 或 API Gateway 来做限流。
2. 请求排队（Message Queue）
避免请求直接被拒绝，保证请求最终被处理
使用 RabbitMQ / Kafka / Redis 等消息队列，将请求存入队列，后端逐步处理。
服务器空闲时从队列中拉取请求，避免因短时间内流量过大导致崩溃。
3. 降级处理（Graceful Degradation）
保证核心功能可用，非核心功能暂时禁用
高峰期时，优先处理重要请求，低优先级请求返回默认值或缓存结果。
可缓存部分响应，减少数据库和计算压力，如 Redis / CDN 预缓存常用数据。
4. 负载均衡（Load Balancing）
扩展服务器能力，提高并发吞吐量
部署多个服务器实例，使用 Nginx / Traefik / Kubernetes 进行负载均衡。
将 1 台服务器的 1000 并发扩展到多台服务器，如 10 台服务器可支持 1 万并发。


### 传入后端的问答数据，有不同的格式，如何根据格式进行分类存储，并且要保证数据的有序性。
格式识别：判断 JSON / XML / 纯文本
解析转换：XML转换为json或者统一转换为QA结构体
分类存储：存入 MySQL / Redis / MongoDB/ 消息队列
保证顺序：使用时间戳、ID进行排序


### RabbitMQ对比Kafka
| 消息模型          |          队列模型（点对点、发布/订阅）                 |   日志模型（消息分区、顺序消费）      |                   |
|--------------|------------------------------------|----------------------------------------|--------------------------------------------------|
| 吞吐量       | 中等（万级 QPS）                   | 极高（百万级 QPS）                     |
| 消息顺序     | 支持严格顺序                       | 分区内有序，全局无序                   |
| 消息持久化   | 基于磁盘存储，但会定期删除消费过的消息 | 日志式存储，消息保留一定时间（默认 7 天） |
| 可靠性       | 支持消息确认机制，保证投递成功     | 高吞吐但可能丢消息（可配合 acks=all 提高可靠性）|
| 事务支持     | 支持事务消息                       | 默认不支持事务（只能用幂等性方式处理）  |
| 消息延迟     | 低（ms 级），适合实时性要求高的场景 | 默认批量处理，延迟较高（秒级）         |
| 扩展性       | 扩展性一般，队列存在性能瓶颈       | 天然分布式，横向扩展性强               |
| 应用场景     | 金融、订单系统、事务处理、低延迟场景 | 日志处理、流式计算、实时数据分析、大数据 |


### 哈希索引
✅ Memory 引擎 默认使用哈希索引
✅ InnoDB 主要使用 B+ 树索引，但有 自适应哈希索引（AHI）（=、in才触发）
✅ 哈希索引适用于 等值查询，但不支持 范围查询
✅ AHI 由 InnoDB 自动管理，如果影响性能可以手动关闭

### 秒杀库存超卖
1. Redis 分布式锁 + Lua
秒杀开始前，将商品库存存入 Redis。
购买时，先用 Redis SETNX 加锁，确保同一时间只有一个线程在修改库存。
用 Lua 脚本原子性地判断库存并减少库存，避免并发问题。
2. 消息队列（MQ）
用户请求先写入消息队列，队列按顺序消费。
后台任务逐步减少库存，避免数据库压力过大。

### IO多路复用
- 监听多个文件描述符（FD）是否就绪（如 socket 是否可读写）
1. select：
早期的多路复用模型。
使用数组或位图管理文件描述符（fd），有最大数量限制（默认1024）。
每次调用都需要遍历所有的fd，性能较差，复杂度为 O(N)。
2. poll：
改进版的select，使用链表管理fd，理论上没有数量限制。
和select类似，仍然是遍历所有的fd，复杂度为 O(N)。
3. epoll：
Linux特有的高效IO多路复用模型。
使用事件驱动机制，注册fd后，内核只返回活跃的fd，避免了遍历所有fd的开销，复杂度为 O(1)。
- Redis就是基于 epoll 的单线程 Reactor

### MYSQL三大日志
| 日志名称   | 日志类型   | 作用范围             | 逻辑 or 物理 | 主要用途                                      |
|------------|------------|----------------------|---------------|-----------------------------------------------|
| undo log   | 回滚日志   | InnoDB（存储引擎层） | 逻辑日志      | 回滚事务、支持 MVCC（快照读）                 |
| redo log   | 重做日志   | InnoDB（存储引擎层） | 物理日志      | 崩溃恢复（Crash Recovery），保证持久性         |
| binlog     | 二进制日志 | MySQL Server 层      | 逻辑日志      | 主从复制、增量备份、数据恢复                   |

### SQL语句执行的流程
1. 查询语句
- 先检查该语句是否有权限，如果没有权限，直接返回错误信息，如果有权限，在 MySQL8.0 版本以前，会先查询缓存，以这条 SQL 语句为 key 在内存中查询是否有结果，如果有直接缓存，如果没有，执行下一步。
- 通过分析器进行词法分析，提取 SQL 语句的关键元素，比如提取上面这个语句是查询 select，提取需要查询的表名为 tb_student，需要查询所有的列，查询条件是这个表的 id='1'。然后判断这个 SQL 语句是否有语法错误，比如关键词是否正确等等，如果检查没问题就执行下一步。
- 接下来就是优化器进行确定执行方案，上面的 SQL 语句，可以有两种执行方案：a.先查询学生表中姓名为“张三”的学生，然后判断是否年龄是 18。b.先找出学生中年龄 18 岁的学生，然后再查询姓名为“张三”的学生。那么优化器根据自己的优化算法进行选择执行效率最好的一个方案（优化器认为，有时候不一定最好）。那么确认了执行计划后就准备开始执行了。
2. 更新语句
- 先查询到张三这一条数据，不会走查询缓存，因为更新语句会导致与该表相关的查询缓存失效。
- 然后拿到查询的语句，把 age 改为 19，然后调用引擎 API 接口，写入这一行数据，InnoDB 引擎把数据保存在内存中，同时记录 redo log，此时 redo log 进入 prepare 状态，然后告诉执行器，执行完成了，随时可以提交。
- 执行器收到通知后记录 binlog，然后调用引擎接口，提交 redo log 为提交状态。
- 更新完成。

### ACID分别实现的手段是什么
A：undo log C：AID I:锁和MVCC D:redo log

### GMP的P的本地队列没有的话，work-stealing机制
首先他会从全局队列拿G，如果全局队列也为空的话，就从其他P中取它本地的一半的G到自己的本地队列里面

### Golang执行的时候到底发生了什么
1. import -> const -> 变量 -> init() -> main()
2. 汇编入口 -> runtime.rt0_go() -> runtime.schedule/init + 其它的初始化 -> runtime.main() -> 自己定义的main()
**runtime.rt0_go()到runtime.main()之间发生的事情：**
- 设置 G（Goroutine）、M（Machine，表示线程）、P（Processor，代表可执行资源）三者关系
- 初始化调度器（M 与 P 的绑定）
- 设置栈、堆内存
- 初始化垃圾回收机制
- 初始化系统线程、信号处理等等

### Golang什么时候会产生死锁
只要用了sync包和channel就有可能产生死锁（除了多个G竞争资源，也有可能是主G阻塞导致所有的G都阻塞，这就是死锁）
- 同步原语中的很多数据结构使用后进行拷贝
- waitgroup中Add()和Done()不匹配
- Mutex和RWMutex加锁解锁不一致或者两个G竞争两个锁
- channel消费者和生产者都要有

### 分布式一致性
强一致性、弱一致性、最终一致性
强一致性：（RAFT->ETCD）三个节点，一个节点接受数据向其他节点发送数据，能得到一半以上的节点返回响应，数据更新才算完成。这种情况，任何时刻所有节点上的数据都是一致的。
- 为什么半数以上就够了：因为就算某些节点当前缺失，它稍后一定会同步过来
弱一致性：（redis集群）第一个节点接收到数据之后，立即返回相应，然后再向其他节点同步数据。这种情况，有可能某些时候各个节点上面的数据是不一致的。

### 跳表和b+树
- 跳表是多级链表
- 性能相对于b+树，查询没有它快，但是插入删除比它快
- 实现起来比b+简单

### 手动加锁的map和sync.Map的区别
| 特性            | 手动加锁的 map               | sync.Map                     |
|----------------|-----------------------------|-----------------------------|
| **实现复杂度**   | 需要自己管理锁               | 内置并发安全，无需手动锁管理  |
| **锁粒度**      | 粗粒度（整个map一把锁）       | 细粒度（内部使用分段锁等优化）|
| **内存占用**    | 通常更低                     | 通常更高（为并发优化牺牲空间）|
| **性能特点**    | 写多读少性能较好             | 读多写少性能极佳（读写分离）             |
| **API 复杂度**  | 使用标准 map API + 锁        | 专用 API (Store/Load/Range 等)|
| **键类型限制**  | 必须可比较                   | 接受任何类型 (`interface{}`) |
| **零值可用性**  | 需要 `make` 初始化           | 零值即可直接使用             |
| **锁的类型**  | 悲观锁           | 乐观锁             |

### gin为什么快
1. 路由匹配快	使用高性能的 前缀树（Radix Tree） 做路由匹配，查找速度非常快。
2. 零内存拷贝（Zero Allocation）	用 sync.Pool 重用上下文对象（gin.Context），大幅减少 GC 压力。
3. 编译时绑定（Handler注册阶段）	路由和 handler 关系在启动时就绑定好，避免运行时频繁计算。
4. 小巧的封装	代码简洁、模块少，避免了很多无谓的抽象。
5. 高效中间件设计	中间件链用数组存储，依次执行，无复杂跳转，性能好。

### linux指令
1. 查看端口是否被占用 lsog -i :8080、netstat -tulnp | grep 8080、ss -tuln | grep 8080
2. 递归创建多层文件夹 mkdir -p a/b/c/d
3. 查看网络连接 netstat -an、ss -an
4. 查看进程的信息 ps aux | grep PID/进程名、ss -tulnp | grep nginx
5. top命令是怎么生效的？
反复读取/proc目录里面的文件（整体CPU使用情况、内存的总量/可用/缓存、系统的负载信息、进程资源使用情况）
6. 文件权限系统、怎么控制文件权限？
文件权限系统：读、写、执行 owner、group、other

ls -l 文件名：-rwxr-xr-- 1 alice dev  1234 Apr 23  test.sh
-rwxr-xr--三个三个读分别对应上面三种角色

r:4, w:2, x:1
chmod 755 file
7 = rwx → 4+2+1
5 = r-x → 4+0+1

7. cpu炸了怎么排查
- top总体来看
- htop图形化界面看
- ps按照cpu使用排序

8. 内存满了如何排查，内存泄露如何排查
free -h查看总体情况
top/ps按照内存使用排序查看进程
watch查看哪个进程实际驻留内存越来越大

9. linux启用一个守护进程、启用一个后台进程
go run main.go &
nohub/setsid go run main.go &



### MYSQL架构
1. 连接层
2. 服务层（SQL层）：解析器、优化器、执行器
3. 存储引擎层：数据的存取
4. 存储系统层：日志文件、临时文件

### docker使用
1. 进入正在运行的容器：docker exec、docker attach
2. build一个镜像：docker build -t <镜像名>:<标签> <Dockerfile所在路径>

### 文件上传失败怎么办？
1.  文件上传到业务服务器失败
客户端传输失败：设置合理的 timeout 和重试机制（例如 axios、fetch 有重试插件）
服务端处理异常：返回错误码 + 错误信息，客户端主动重试
可以使用 上传任务记录表 或 Redis 暂存：业务服务宕机也不丢数据

2. 业务服务器上传 Ceph 失败
使用 重试机制 + 异步任务队列（RabbitMQ）
上传失败写入 MQ 的 “失败队列” 中，自动/手动重试
Ceph写入成功但元数据写失败：使用 本地事务 + 分布式事务补偿 或最终一致性


### 快照读与当前读？
1. 快照读（一致性非锁定读）就是单纯的select
- 快照即记录的历史版本，每行记录可能存在多个历史版本（多版本技术）。
- 快照读的情况下，如果读取的记录正在执行 UPDATE/DELETE 操作，读取操作不会因此去等待记录上 X 锁的释放，而是会去读取行的一个快照
- 只有在事务隔离级别 RC(读取已提交) 和 RR（可重读）下，InnoDB 才会使用一致性非锁定读：在 RC 级别下，对于快照数据，一致性非锁定读总是读取被锁定行的最新一份快照数据。在 RR 级别下，对于快照数据，一致性非锁定读总是读取本事务开始时的行数据版本。
- 快照读比较适合对于数据一致性要求不是特别高且追求极致性能的业务场景。

2. 当前读 （一致性锁定读）就是给行记录加 X 锁或 S 锁。
```sql
# 对读的记录加一个X锁
SELECT...FOR UPDATE
# 对读的记录加一个S锁
SELECT...LOCK IN SHARE MODE
# 对读的记录加一个S锁
SELECT...FOR SHARE
# 对修改的记录加一个X锁
INSERT...
UPDATE...
DELETE...
```

### 介绍一下TCP/IP模型
TCP/IP 模型就是指导数据如何从你的软件→打包→找路→传到别人家电脑的完整分层机制。每一层只关注自己的事，彼此协作，就像物流系统一样高效可靠。

### 为什么不对性别启用一个索引
- 性别字段的“区分度低”
- 索引扫描成本 ≈ 全表扫描成本

### TCP拥塞控制与修改门限值
1. TCP 拥塞控制的四个阶段（核心）
**慢启动（Slow Start）**
初始拥塞窗口很小（通常是 1 MSS）。
每收到一个 ACK，就把窗口大小翻倍（指数增长）。
快速探测出网络带宽的可用范围。
**拥塞避免（Congestion Avoidance）**
当达到“慢启动门限（ssthresh）”时，进入线性增长阶段。
每个 RTT（往返时延）只增加 1 MSS，慢慢试探。
**快速重传（Fast Retransmit）**
收到 3 个重复 ACK，说明某个包可能丢了，马上重传。
**快速恢复（Fast Recovery）**
不回到慢启动，而是减半窗口再线性增长，维持一定传输速率。

2. 为什么要修改门限（ssthresh）？
- 🧠 ssthresh 决定了从“快速增长”到“慢速增长”的切换点。
如果发生丢包，说明网络已经拥塞了。
TCP 会：
把 ssthresh 设置为当前窗口的一半。
拥塞窗口回到 1（或退回一半，取决于版本）。
重新进行慢启动（或者快速恢复）。
- 这样可以：
抑制发送速率，缓解网络压力；
防止继续加速带来更严重的丢包和拥塞。

3. 不修改门限会带来什么问题？
假设丢包了，但我们不更新门限值（ssthresh）：
下一次慢启动就会增长到原来的门限（比如还是100），
而现在网络可能最多只能承受60，
这样又会引发新一轮的丢包，进入**“发送-丢包-回退”的恶性循环**，
网络稳定性变差，吞吐率降低，延迟升高。

### 假设我们对一个text字段做了索引，那么这个时候它的查找速度会不会快？如果快或者不快的话，它是一个怎么寻址的过程？比如说他在寻址过程中要二分，他是根据什么去做的？二分怎么做的排序？

- 会
- 输入 'Kafka and Streams'。
从根节点开始，比较目标字符串和当前节点的键值，用字典序判断大小。
类似二分查找，沿着比它小/大的方向走，直到找到对应的叶子节点。
定位记录
叶子节点中存有目标 title 对应的主键（或整行记录，如果是聚簇索引）。
若为辅助索引，还需“回表”读取整行。
- 它是按字典序排序的，查找路径就像查字典那样走树
- 字符串按照字符集排序

### GPU虚拟化和混部是什么意思？
GPU虚拟化关注的是单个GPU资源的拆分与共享，而混部更强调在系统层面整合多样化的负载。
​​协同场景​​：在混部环境中，可通过虚拟化将一块物理GPU分配给多个容器/Pod，分别运行不同优先级的任务（如高优先级的推理+低优先级的模型训练）。

### 为什么一个游戏那么大，却能在一个这么小的内存上运行？
- 启动时加载核心引擎和首场景（约2GB）
- 玩家移动时后台线程流式加载200米范围内的资源
- 显存管理模块自动将不可见区域的4K纹理替换为1K版本
- 物理引擎仅计算可视范围内的碰撞体
- 当内存压力达到阈值时，自动触发资源回收机制
- 资源复用、多级缓存、数据压缩

### cookie、session、jwt之间的区别？
- cookie是存在浏览器（客户端）中的，一般可以在里面存session ID
- session是存在服务端的，比如说存用户的信息、权限
- 这样cookie和session之间就可以协同工作，用户每次请求的时候将cookie对应的数据也上传至服务端，服务端按照session ID找到用户的信息和权限，根据权限来做一些反馈
- 但是这样的模式对session的压力很大，而且cookie是针对浏览器的，移动端无法使用
- jwt是一种 令牌（token），用户认证后服务器生成并返回，可以存在客户端的cookie或者内存，不需要服务端保存用户信息，功能强大，而且适合微服务的架构（本地签名的认证）。

### 调用open api的流程
- 消息头部比较重要的就是Authorization，写你注册得到的apikey
- 消息体里面写model的名称、messages的内容、temperature随机值、max_token返回内容的最大token长度

### 外部请求是怎么访问到docker内部的容器还有k8s内部的pod的
- Docker 外部访问： 通过 -p 参数映射宿主机端口到容器端口，外部请求访问宿主机IP和映射端口。

- Kubernetes 外部访问：
NodePort: 在每个节点暴露端口，通过 <NodeIP>:<NodePort> 访问。
LoadBalancer: 请求云服务商创建外部负载均衡器，提供公网 IP。
Ingress: 通过 Ingress Controller 和规则，基于域名和路径路由外部请求到 Service。

### pod内部和之间的网络请求
同一个 Pod 内的容器之间的互相访问：